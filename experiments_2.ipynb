{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from helper_functions import get_classification_report\n",
    "from helper_functions import create_tf_data_datasets_contrastive\n",
    "from helper_functions import create_tf_data_testset_contrastive\n",
    "from helper_functions import euclidean_distance\n",
    "from helper_functions import manhattan_distance\n",
    "from helper_functions import contrastive_loss\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras import mixed_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def AlexNet(height, width, channels):\n",
    "\n",
    "    X_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    X = keras.layers.Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 ,name='bn1')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn4')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
    "\n",
    "    X = keras.layers.Flatten()(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'sigmoid', name = 'fc1')(X)\n",
    "\n",
    "    model = keras.models.Model(inputs = X_input, outputs = X, name='AlexNet')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def half_deep_writer(height, width, channels):\n",
    "\n",
    "    input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    x = keras.layers.Conv2D(96, kernel_size=5, strides=2, activation='relu')(input)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\",  activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "    output = keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "    model = keras.models.Model(input, output)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alexnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2330cufh\" target=\"_blank\">clear-paper-82</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 69s 180ms/step - loss: 0.2205 - accuracy: 0.6626 - val_loss: 0.2291 - val_accuracy: 0.6202\nEpoch 2/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2128 - accuracy: 0.6694 - val_loss: 0.2588 - val_accuracy: 0.5252\nEpoch 3/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2090 - accuracy: 0.6741 - val_loss: 0.2761 - val_accuracy: 0.6213\nEpoch 4/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2152 - accuracy: 0.6686 - val_loss: 0.2653 - val_accuracy: 0.4989\nEpoch 5/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2157 - accuracy: 0.6663 - val_loss: 0.2749 - val_accuracy: 0.5853\nEpoch 6/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2092 - accuracy: 0.6758 - val_loss: 0.2726 - val_accuracy: 0.5025\nEpoch 7/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2087 - accuracy: 0.6708 - val_loss: 0.2078 - val_accuracy: 0.6689\nEpoch 8/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2054 - accuracy: 0.6774 - val_loss: 0.2029 - val_accuracy: 0.6791\nEpoch 9/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2022 - accuracy: 0.6809 - val_loss: 0.1983 - val_accuracy: 0.6876\nEpoch 10/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.2015 - accuracy: 0.6804 - val_loss: 0.2001 - val_accuracy: 0.6796\nEpoch 11/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1991 - accuracy: 0.6841 - val_loss: 0.2000 - val_accuracy: 0.6770\nEpoch 12/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1979 - accuracy: 0.6852 - val_loss: 0.2016 - val_accuracy: 0.6875\nEpoch 13/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1983 - accuracy: 0.6830 - val_loss: 0.1963 - val_accuracy: 0.6863\nEpoch 14/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1978 - accuracy: 0.6815 - val_loss: 0.1982 - val_accuracy: 0.6769\nEpoch 15/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1976 - accuracy: 0.6835 - val_loss: 0.1962 - val_accuracy: 0.6848\nEpoch 16/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1956 - accuracy: 0.6835 - val_loss: 0.2098 - val_accuracy: 0.6811\nEpoch 17/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1961 - accuracy: 0.6827 - val_loss: 0.2010 - val_accuracy: 0.6744\nEpoch 18/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1945 - accuracy: 0.6847 - val_loss: 0.1929 - val_accuracy: 0.6828\nEpoch 19/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1940 - accuracy: 0.6845 - val_loss: 0.1915 - val_accuracy: 0.6885\nEpoch 20/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1927 - accuracy: 0.6970 - val_loss: 0.2014 - val_accuracy: 0.6873\nEpoch 21/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1915 - accuracy: 0.7153 - val_loss: 0.1940 - val_accuracy: 0.7085\nEpoch 22/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1914 - accuracy: 0.7144 - val_loss: 0.1889 - val_accuracy: 0.7209\nEpoch 23/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1899 - accuracy: 0.7181 - val_loss: 0.2192 - val_accuracy: 0.6637\nEpoch 24/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1896 - accuracy: 0.7192 - val_loss: 0.1880 - val_accuracy: 0.7184\nEpoch 25/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1890 - accuracy: 0.7184 - val_loss: 0.1887 - val_accuracy: 0.7182\nEpoch 26/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1878 - accuracy: 0.7243 - val_loss: 0.1890 - val_accuracy: 0.7204\nEpoch 27/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1869 - accuracy: 0.7266 - val_loss: 0.1876 - val_accuracy: 0.7314\nEpoch 28/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1848 - accuracy: 0.7314 - val_loss: 0.1871 - val_accuracy: 0.7230\nEpoch 29/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1839 - accuracy: 0.7327 - val_loss: 0.1829 - val_accuracy: 0.7376\nEpoch 30/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1843 - accuracy: 0.7338 - val_loss: 0.1847 - val_accuracy: 0.7294\nEpoch 31/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1823 - accuracy: 0.7381 - val_loss: 0.1776 - val_accuracy: 0.7461\nEpoch 32/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1803 - accuracy: 0.7425 - val_loss: 0.1788 - val_accuracy: 0.7421\nEpoch 33/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1798 - accuracy: 0.7403 - val_loss: 0.1768 - val_accuracy: 0.7455\nEpoch 34/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1776 - accuracy: 0.7448 - val_loss: 0.1844 - val_accuracy: 0.7277\nEpoch 35/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1742 - accuracy: 0.7555 - val_loss: 0.1915 - val_accuracy: 0.7032\nEpoch 36/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1716 - accuracy: 0.7589 - val_loss: 0.1761 - val_accuracy: 0.7428\nEpoch 37/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1720 - accuracy: 0.7583 - val_loss: 0.1888 - val_accuracy: 0.7394\nEpoch 38/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1673 - accuracy: 0.7673 - val_loss: 0.1803 - val_accuracy: 0.7455\nEpoch 39/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1623 - accuracy: 0.7781 - val_loss: 0.1721 - val_accuracy: 0.7663\nEpoch 40/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1593 - accuracy: 0.7829 - val_loss: 0.1614 - val_accuracy: 0.7816\nEpoch 41/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1568 - accuracy: 0.7930 - val_loss: 0.1592 - val_accuracy: 0.7950\nEpoch 42/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1550 - accuracy: 0.7947 - val_loss: 0.1583 - val_accuracy: 0.7922\nEpoch 43/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1548 - accuracy: 0.7950 - val_loss: 0.1633 - val_accuracy: 0.7671\nEpoch 44/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1522 - accuracy: 0.7995 - val_loss: 0.1755 - val_accuracy: 0.7661\nEpoch 45/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1520 - accuracy: 0.8014 - val_loss: 0.1831 - val_accuracy: 0.7432\nEpoch 46/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1509 - accuracy: 0.8059 - val_loss: 0.1949 - val_accuracy: 0.6898\nEpoch 47/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1495 - accuracy: 0.8064 - val_loss: 0.1752 - val_accuracy: 0.7414\nEpoch 48/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1470 - accuracy: 0.8127 - val_loss: 0.1487 - val_accuracy: 0.8140\nEpoch 49/50\n286/286 [==============================] - 55s 175ms/step - loss: 0.1471 - accuracy: 0.8141 - val_loss: 0.1475 - val_accuracy: 0.8105\nEpoch 50/50\n286/286 [==============================] - 55s 176ms/step - loss: 0.1459 - accuracy: 0.8147 - val_loss: 0.1437 - val_accuracy: 0.8192\n"
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Crossentropy - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/1ejxvo4k\" target=\"_blank\">stoic-haze-95</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 64s 178ms/step - loss: 0.6133 - accuracy: 0.6622 - val_loss: 0.7534 - val_accuracy: 0.6017\nEpoch 2/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5912 - accuracy: 0.6770 - val_loss: 0.6438 - val_accuracy: 0.6420\nEpoch 3/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5834 - accuracy: 0.6811 - val_loss: 0.7140 - val_accuracy: 0.6462\nEpoch 4/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5781 - accuracy: 0.6823 - val_loss: 0.5918 - val_accuracy: 0.6795\nEpoch 5/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5737 - accuracy: 0.6861 - val_loss: 0.6932 - val_accuracy: 0.5934\nEpoch 6/50\n286/286 [==============================] - 55s 173ms/step - loss: 0.5690 - accuracy: 0.6855 - val_loss: 0.5794 - val_accuracy: 0.6777\nEpoch 7/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5711 - accuracy: 0.6849 - val_loss: 0.7822 - val_accuracy: 0.5380\nEpoch 8/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5715 - accuracy: 0.6863 - val_loss: 0.7446 - val_accuracy: 0.5028\nEpoch 9/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5691 - accuracy: 0.6868 - val_loss: 0.7219 - val_accuracy: 0.6485\nEpoch 10/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5648 - accuracy: 0.6893 - val_loss: 0.5568 - val_accuracy: 0.6975\nEpoch 11/50\n286/286 [==============================] - 55s 173ms/step - loss: 0.5636 - accuracy: 0.6883 - val_loss: 0.5581 - val_accuracy: 0.6888\nEpoch 12/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5641 - accuracy: 0.6895 - val_loss: 0.5729 - val_accuracy: 0.6796\nEpoch 13/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5647 - accuracy: 0.6867 - val_loss: 0.7354 - val_accuracy: 0.5094\nEpoch 14/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5597 - accuracy: 0.6886 - val_loss: 0.9326 - val_accuracy: 0.5229\nEpoch 15/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5527 - accuracy: 0.6924 - val_loss: 0.5531 - val_accuracy: 0.6914\nEpoch 16/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5457 - accuracy: 0.7073 - val_loss: 0.7383 - val_accuracy: 0.5953\nEpoch 17/50\n286/286 [==============================] - 54s 174ms/step - loss: 0.5391 - accuracy: 0.7295 - val_loss: 0.7500 - val_accuracy: 0.6538\nEpoch 18/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5501 - accuracy: 0.7136 - val_loss: 0.5897 - val_accuracy: 0.6815\nEpoch 19/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5361 - accuracy: 0.7335 - val_loss: 0.5916 - val_accuracy: 0.6785\nEpoch 20/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5196 - accuracy: 0.7453 - val_loss: 0.6354 - val_accuracy: 0.7070\nEpoch 21/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.5076 - accuracy: 0.7534 - val_loss: 0.4974 - val_accuracy: 0.7621\nEpoch 22/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.5014 - accuracy: 0.7588 - val_loss: 0.5055 - val_accuracy: 0.7495\nEpoch 23/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4985 - accuracy: 0.7620 - val_loss: 0.5303 - val_accuracy: 0.7486\nEpoch 24/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4967 - accuracy: 0.7642 - val_loss: 0.4959 - val_accuracy: 0.7596\nEpoch 25/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4946 - accuracy: 0.7645 - val_loss: 0.4977 - val_accuracy: 0.7627\nEpoch 26/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4928 - accuracy: 0.7650 - val_loss: 0.4963 - val_accuracy: 0.7633\nEpoch 27/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4929 - accuracy: 0.7655 - val_loss: 0.4906 - val_accuracy: 0.7657\nEpoch 28/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4942 - accuracy: 0.7647 - val_loss: 0.4911 - val_accuracy: 0.7688\nEpoch 29/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4897 - accuracy: 0.7678 - val_loss: 0.4935 - val_accuracy: 0.7596\nEpoch 30/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4863 - accuracy: 0.7682 - val_loss: 0.4893 - val_accuracy: 0.7657\nEpoch 31/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4889 - accuracy: 0.7668 - val_loss: 0.4914 - val_accuracy: 0.7659\nEpoch 32/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4865 - accuracy: 0.7680 - val_loss: 0.5017 - val_accuracy: 0.7631\nEpoch 33/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4846 - accuracy: 0.7703 - val_loss: 0.4976 - val_accuracy: 0.7641\nEpoch 34/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4837 - accuracy: 0.7718 - val_loss: 0.4816 - val_accuracy: 0.7730\nEpoch 35/50\n286/286 [==============================] - 54s 174ms/step - loss: 0.4827 - accuracy: 0.7720 - val_loss: 0.4896 - val_accuracy: 0.7697\nEpoch 36/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4844 - accuracy: 0.7706 - val_loss: 0.4831 - val_accuracy: 0.7661\nEpoch 37/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4803 - accuracy: 0.7734 - val_loss: 0.4800 - val_accuracy: 0.7696\nEpoch 38/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4787 - accuracy: 0.7733 - val_loss: 0.4765 - val_accuracy: 0.7706\nEpoch 39/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4778 - accuracy: 0.7744 - val_loss: 0.5210 - val_accuracy: 0.7523\nEpoch 40/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4754 - accuracy: 0.7750 - val_loss: 0.4761 - val_accuracy: 0.7755\nEpoch 41/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4725 - accuracy: 0.7765 - val_loss: 0.5047 - val_accuracy: 0.7658\nEpoch 42/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4710 - accuracy: 0.7773 - val_loss: 0.4691 - val_accuracy: 0.7759\nEpoch 43/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4688 - accuracy: 0.7777 - val_loss: 0.4657 - val_accuracy: 0.7862\nEpoch 44/50\n286/286 [==============================] - 54s 174ms/step - loss: 0.4667 - accuracy: 0.7832 - val_loss: 0.4804 - val_accuracy: 0.7755\nEpoch 45/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4628 - accuracy: 0.7834 - val_loss: 0.4885 - val_accuracy: 0.7709\nEpoch 46/50\n286/286 [==============================] - 54s 174ms/step - loss: 0.4591 - accuracy: 0.7937 - val_loss: 0.4623 - val_accuracy: 0.7940\nEpoch 47/50\n286/286 [==============================] - 55s 174ms/step - loss: 0.4586 - accuracy: 0.7958 - val_loss: 0.4633 - val_accuracy: 0.7930\nEpoch 48/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4559 - accuracy: 0.7991 - val_loss: 0.5042 - val_accuracy: 0.7501\nEpoch 49/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4540 - accuracy: 0.8014 - val_loss: 0.4574 - val_accuracy: 0.7974\nEpoch 50/50\n286/286 [==============================] - 54s 173ms/step - loss: 0.4538 - accuracy: 0.8029 - val_loss: 0.4668 - val_accuracy: 0.7977\n"
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Manhatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 65s 185ms/step - loss: 0.4995 - accuracy: 0.5005 - val_loss: 0.5025 - val_accuracy: 0.4975\nEpoch 2/50\n286/286 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.5005"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-f4a696a6f725>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0msiamese_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcontrastive_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Adam\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mhistory_siamese_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msiamese_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReduceLROnPlateau\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"val_loss\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mWandbCallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/wandb/integration/keras/keras.py\u001B[0m in \u001B[0;36mnew_v2\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mcbk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcbks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m                 \u001B[0mset_wandb_attrs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcbk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mold_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m     \u001B[0mtraining_arrays\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0morig_fit_loop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mold_arrays\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1223\u001B[0m               \u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1224\u001B[0m               \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1225\u001B[0;31m               _use_cached_eval_dataset=True)\n\u001B[0m\u001B[1;32m   1226\u001B[0m           \u001B[0mval_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'val_'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mval_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1227\u001B[0m           \u001B[0mepoch_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1487\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1488\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1489\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1490\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1491\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    922\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    923\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 924\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    925\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    926\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 3024\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1960\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1961\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1963\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(manhattan_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Half DeepWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/3qa9jwgq\" target=\"_blank\">major-water-79</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 95s 255ms/step - loss: 0.2202 - accuracy: 0.5964 - val_loss: 0.2030 - val_accuracy: 0.6824\nEpoch 2/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1987 - accuracy: 0.7048 - val_loss: 0.1860 - val_accuracy: 0.7404\nEpoch 3/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1810 - accuracy: 0.7480 - val_loss: 0.1754 - val_accuracy: 0.7636\nEpoch 4/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1695 - accuracy: 0.7690 - val_loss: 0.1634 - val_accuracy: 0.7850\nEpoch 5/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1624 - accuracy: 0.7792 - val_loss: 0.1557 - val_accuracy: 0.7933\nEpoch 6/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1552 - accuracy: 0.7925 - val_loss: 0.1533 - val_accuracy: 0.7907\nEpoch 7/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1479 - accuracy: 0.8036 - val_loss: 0.1399 - val_accuracy: 0.8239\nEpoch 8/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1416 - accuracy: 0.8117 - val_loss: 0.1412 - val_accuracy: 0.8131\nEpoch 9/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1354 - accuracy: 0.8206 - val_loss: 0.1322 - val_accuracy: 0.8242\nEpoch 10/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1318 - accuracy: 0.8254 - val_loss: 0.1289 - val_accuracy: 0.8316\nEpoch 11/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1326 - accuracy: 0.8225 - val_loss: 0.1515 - val_accuracy: 0.7873\nEpoch 12/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1404 - accuracy: 0.8052 - val_loss: 0.1226 - val_accuracy: 0.8380\nEpoch 13/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1275 - accuracy: 0.8279 - val_loss: 0.1219 - val_accuracy: 0.8376\nEpoch 14/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1215 - accuracy: 0.8372 - val_loss: 0.1148 - val_accuracy: 0.8485\nEpoch 15/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1192 - accuracy: 0.8406 - val_loss: 0.1165 - val_accuracy: 0.8438\nEpoch 16/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1165 - accuracy: 0.8447 - val_loss: 0.1126 - val_accuracy: 0.8506\nEpoch 17/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1133 - accuracy: 0.8503 - val_loss: 0.1162 - val_accuracy: 0.8402\nEpoch 18/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1110 - accuracy: 0.8530 - val_loss: 0.1097 - val_accuracy: 0.8538\nEpoch 19/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1079 - accuracy: 0.8581 - val_loss: 0.1058 - val_accuracy: 0.8606\nEpoch 20/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1069 - accuracy: 0.8585 - val_loss: 0.1048 - val_accuracy: 0.8635\nEpoch 21/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1060 - accuracy: 0.8582 - val_loss: 0.1006 - val_accuracy: 0.8680\nEpoch 22/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1050 - accuracy: 0.8612 - val_loss: 0.1041 - val_accuracy: 0.8618\nEpoch 23/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1019 - accuracy: 0.8646 - val_loss: 0.0987 - val_accuracy: 0.8712\nEpoch 24/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1024 - accuracy: 0.8641 - val_loss: 0.1004 - val_accuracy: 0.8677\nEpoch 25/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1020 - accuracy: 0.8649 - val_loss: 0.0963 - val_accuracy: 0.8713\nEpoch 26/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0998 - accuracy: 0.8673 - val_loss: 0.1055 - val_accuracy: 0.8582\nEpoch 27/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0991 - accuracy: 0.8679 - val_loss: 0.0950 - val_accuracy: 0.8735\nEpoch 28/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0973 - accuracy: 0.8710 - val_loss: 0.0993 - val_accuracy: 0.8684\nEpoch 29/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0974 - accuracy: 0.8713 - val_loss: 0.0994 - val_accuracy: 0.8673\nEpoch 30/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0970 - accuracy: 0.8713 - val_loss: 0.0940 - val_accuracy: 0.8785\nEpoch 31/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0978 - accuracy: 0.8702 - val_loss: 0.0919 - val_accuracy: 0.8797\nEpoch 32/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0958 - accuracy: 0.8723 - val_loss: 0.0914 - val_accuracy: 0.8790\nEpoch 33/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0939 - accuracy: 0.8760 - val_loss: 0.0941 - val_accuracy: 0.8746\nEpoch 34/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0931 - accuracy: 0.8775 - val_loss: 0.0908 - val_accuracy: 0.8792\nEpoch 35/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0918 - accuracy: 0.8781 - val_loss: 0.0905 - val_accuracy: 0.8807\nEpoch 36/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0917 - accuracy: 0.8784 - val_loss: 0.0874 - val_accuracy: 0.8866\nEpoch 37/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0914 - accuracy: 0.8794 - val_loss: 0.0998 - val_accuracy: 0.8645\nEpoch 38/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0891 - accuracy: 0.8814 - val_loss: 0.0871 - val_accuracy: 0.8872\nEpoch 39/50\n286/286 [==============================] - 74s 241ms/step - loss: 0.0884 - accuracy: 0.8836 - val_loss: 0.0952 - val_accuracy: 0.8718\nEpoch 40/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0884 - accuracy: 0.8832 - val_loss: 0.0834 - val_accuracy: 0.8907\nEpoch 41/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0868 - accuracy: 0.8851 - val_loss: 0.0878 - val_accuracy: 0.8853\nEpoch 42/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.0881 - accuracy: 0.8840 - val_loss: 0.0805 - val_accuracy: 0.8969\nEpoch 43/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.0851 - accuracy: 0.8882 - val_loss: 0.0897 - val_accuracy: 0.8796\nEpoch 44/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0851 - accuracy: 0.8883 - val_loss: 0.0869 - val_accuracy: 0.8862\nEpoch 45/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0846 - accuracy: 0.8886 - val_loss: 0.0810 - val_accuracy: 0.8942\nEpoch 46/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0843 - accuracy: 0.8891 - val_loss: 0.0814 - val_accuracy: 0.8919\nEpoch 47/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0831 - accuracy: 0.8908 - val_loss: 0.0825 - val_accuracy: 0.8917\nEpoch 48/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0743 - accuracy: 0.9056 - val_loss: 0.0722 - val_accuracy: 0.9085\nEpoch 49/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0729 - accuracy: 0.9072 - val_loss: 0.0720 - val_accuracy: 0.9089\nEpoch 50/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.0730 - accuracy: 0.9073 - val_loss: 0.0725 - val_accuracy: 0.9074\n"
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Eucledian - 113x113"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 113, 113, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2plv4e6f\" target=\"_blank\">polished-butterfly-129</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "566/566 [==============================] - 70s 53ms/step - loss: 0.2189 - accuracy: 0.6292 - val_loss: 0.1866 - val_accuracy: 0.7411\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1805 - accuracy: 0.7468 - val_loss: 0.1706 - val_accuracy: 0.7739\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.1651 - accuracy: 0.7705 - val_loss: 0.1941 - val_accuracy: 0.7085\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.1605 - accuracy: 0.7728 - val_loss: 0.1524 - val_accuracy: 0.7832\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1535 - accuracy: 0.7855 - val_loss: 0.1527 - val_accuracy: 0.7855\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1509 - accuracy: 0.7873 - val_loss: 0.1481 - val_accuracy: 0.7940\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1459 - accuracy: 0.7956 - val_loss: 0.1399 - val_accuracy: 0.8133\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1362 - accuracy: 0.8137 - val_loss: 0.1364 - val_accuracy: 0.8152\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1311 - accuracy: 0.8212 - val_loss: 0.1241 - val_accuracy: 0.8307\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1287 - accuracy: 0.8230 - val_loss: 0.1317 - val_accuracy: 0.8172\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1256 - accuracy: 0.8273 - val_loss: 0.1254 - val_accuracy: 0.8271\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1240 - accuracy: 0.8302 - val_loss: 0.1220 - val_accuracy: 0.8327\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1246 - accuracy: 0.8296 - val_loss: 0.1260 - val_accuracy: 0.8236\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1226 - accuracy: 0.8328 - val_loss: 0.1174 - val_accuracy: 0.8396\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1205 - accuracy: 0.8353 - val_loss: 0.1169 - val_accuracy: 0.8404\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1168 - accuracy: 0.8419 - val_loss: 0.1158 - val_accuracy: 0.8432\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.1117 - accuracy: 0.8500 - val_loss: 0.1107 - val_accuracy: 0.8504\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1121 - accuracy: 0.8496 - val_loss: 0.1070 - val_accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1097 - accuracy: 0.8526 - val_loss: 0.1146 - val_accuracy: 0.8423\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1080 - accuracy: 0.8553 - val_loss: 0.1094 - val_accuracy: 0.8538\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1067 - accuracy: 0.8575 - val_loss: 0.1073 - val_accuracy: 0.8535\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1070 - accuracy: 0.8568 - val_loss: 0.1105 - val_accuracy: 0.8503\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1054 - accuracy: 0.8580 - val_loss: 0.1068 - val_accuracy: 0.8565\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1055 - accuracy: 0.8592 - val_loss: 0.1063 - val_accuracy: 0.8565\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1047 - accuracy: 0.8590 - val_loss: 0.1127 - val_accuracy: 0.8465\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1045 - accuracy: 0.8601 - val_loss: 0.1013 - val_accuracy: 0.8640\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1037 - accuracy: 0.8604 - val_loss: 0.0996 - val_accuracy: 0.8670\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1037 - accuracy: 0.8619 - val_loss: 0.1093 - val_accuracy: 0.8515\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1028 - accuracy: 0.8640 - val_loss: 0.0991 - val_accuracy: 0.8692\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1006 - accuracy: 0.8665 - val_loss: 0.0978 - val_accuracy: 0.8705\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1000 - accuracy: 0.8669 - val_loss: 0.1014 - val_accuracy: 0.8665\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.1002 - accuracy: 0.8664 - val_loss: 0.1044 - val_accuracy: 0.8631\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0999 - accuracy: 0.8660 - val_loss: 0.1004 - val_accuracy: 0.8659\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0999 - accuracy: 0.8676 - val_loss: 0.1001 - val_accuracy: 0.8665\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0973 - accuracy: 0.8703 - val_loss: 0.0953 - val_accuracy: 0.8738\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0981 - accuracy: 0.8700 - val_loss: 0.0973 - val_accuracy: 0.8692\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0981 - accuracy: 0.8698 - val_loss: 0.0995 - val_accuracy: 0.8675\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0976 - accuracy: 0.8701 - val_loss: 0.0950 - val_accuracy: 0.8725\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0973 - accuracy: 0.8703 - val_loss: 0.0945 - val_accuracy: 0.8750\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0967 - accuracy: 0.8710 - val_loss: 0.0942 - val_accuracy: 0.8748\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0954 - accuracy: 0.8724 - val_loss: 0.0931 - val_accuracy: 0.8771\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0957 - accuracy: 0.8732 - val_loss: 0.0922 - val_accuracy: 0.8798\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0951 - accuracy: 0.8726 - val_loss: 0.0873 - val_accuracy: 0.8855\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0928 - accuracy: 0.8768 - val_loss: 0.0966 - val_accuracy: 0.8705\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0939 - accuracy: 0.8754 - val_loss: 0.0866 - val_accuracy: 0.8877\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0922 - accuracy: 0.8780 - val_loss: 0.0965 - val_accuracy: 0.8668\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0919 - accuracy: 0.8782 - val_loss: 0.0881 - val_accuracy: 0.8860\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0917 - accuracy: 0.8794 - val_loss: 0.0868 - val_accuracy: 0.8869\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0914 - accuracy: 0.8786 - val_loss: 0.0907 - val_accuracy: 0.8805\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.0910 - accuracy: 0.8793 - val_loss: 0.0888 - val_accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Crossentropy - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2ab2yq59\" target=\"_blank\">lively-dust-94</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 96s 257ms/step - loss: 0.6322 - accuracy: 0.5819 - val_loss: 0.6022 - val_accuracy: 0.6479\nEpoch 2/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.5784 - accuracy: 0.6896 - val_loss: 0.5426 - val_accuracy: 0.7005\nEpoch 3/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.5210 - accuracy: 0.7400 - val_loss: 0.5009 - val_accuracy: 0.7491\nEpoch 4/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4956 - accuracy: 0.7622 - val_loss: 0.4810 - val_accuracy: 0.7766\nEpoch 5/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4805 - accuracy: 0.7714 - val_loss: 0.4682 - val_accuracy: 0.7868\nEpoch 6/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.4749 - accuracy: 0.7766 - val_loss: 0.4539 - val_accuracy: 0.7866\nEpoch 7/50\n286/286 [==============================] - 75s 243ms/step - loss: 0.4490 - accuracy: 0.7979 - val_loss: 0.4356 - val_accuracy: 0.8104\nEpoch 8/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4253 - accuracy: 0.8143 - val_loss: 0.4098 - val_accuracy: 0.8236\nEpoch 9/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4088 - accuracy: 0.8247 - val_loss: 0.4267 - val_accuracy: 0.8070\nEpoch 10/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4111 - accuracy: 0.8178 - val_loss: 0.4082 - val_accuracy: 0.8240\nEpoch 11/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.4027 - accuracy: 0.8215 - val_loss: 0.4099 - val_accuracy: 0.8178\nEpoch 12/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3945 - accuracy: 0.8252 - val_loss: 0.3829 - val_accuracy: 0.8315\nEpoch 13/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.3821 - accuracy: 0.8339 - val_loss: 0.3812 - val_accuracy: 0.8320\nEpoch 14/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3743 - accuracy: 0.8375 - val_loss: 0.3635 - val_accuracy: 0.8419\nEpoch 15/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3629 - accuracy: 0.8448 - val_loss: 0.3520 - val_accuracy: 0.8522\nEpoch 16/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3626 - accuracy: 0.8440 - val_loss: 0.3419 - val_accuracy: 0.8586\nEpoch 17/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3549 - accuracy: 0.8487 - val_loss: 0.3449 - val_accuracy: 0.8509\nEpoch 18/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.3419 - val_accuracy: 0.8520\nEpoch 19/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3427 - accuracy: 0.8549 - val_loss: 0.3325 - val_accuracy: 0.8608\nEpoch 20/50\n286/286 [==============================] - 75s 243ms/step - loss: 0.3433 - accuracy: 0.8529 - val_loss: 0.3893 - val_accuracy: 0.8264\nEpoch 21/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3330 - accuracy: 0.8594 - val_loss: 0.3541 - val_accuracy: 0.8469\nEpoch 22/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3384 - accuracy: 0.8551 - val_loss: 0.3259 - val_accuracy: 0.8618\nEpoch 23/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.3299 - accuracy: 0.8602 - val_loss: 0.3176 - val_accuracy: 0.8673\nEpoch 24/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3210 - accuracy: 0.8654 - val_loss: 0.3244 - val_accuracy: 0.8613\nEpoch 25/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3248 - accuracy: 0.8632 - val_loss: 0.3228 - val_accuracy: 0.8652\nEpoch 26/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3215 - accuracy: 0.8647 - val_loss: 0.3144 - val_accuracy: 0.8684\nEpoch 27/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.3144 - accuracy: 0.8691 - val_loss: 0.3386 - val_accuracy: 0.8559\nEpoch 28/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3201 - accuracy: 0.8650 - val_loss: 0.3050 - val_accuracy: 0.8741\nEpoch 29/50\n286/286 [==============================] - 75s 243ms/step - loss: 0.3145 - accuracy: 0.8677 - val_loss: 0.3149 - val_accuracy: 0.8682\nEpoch 30/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3082 - accuracy: 0.8720 - val_loss: 0.2956 - val_accuracy: 0.8770\nEpoch 31/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.3082 - accuracy: 0.8724 - val_loss: 0.3206 - val_accuracy: 0.8612\nEpoch 32/50\n286/286 [==============================] - 75s 243ms/step - loss: 0.3048 - accuracy: 0.8734 - val_loss: 0.2894 - val_accuracy: 0.8833\nEpoch 33/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.3044 - accuracy: 0.8731 - val_loss: 0.3174 - val_accuracy: 0.8657\nEpoch 34/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2971 - accuracy: 0.8769 - val_loss: 0.2860 - val_accuracy: 0.8831\nEpoch 35/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2990 - accuracy: 0.8756 - val_loss: 0.2890 - val_accuracy: 0.8802\nEpoch 36/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2941 - accuracy: 0.8783 - val_loss: 0.3042 - val_accuracy: 0.8731\nEpoch 37/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2960 - accuracy: 0.8776 - val_loss: 0.2760 - val_accuracy: 0.8875\nEpoch 38/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2925 - accuracy: 0.8782 - val_loss: 0.2775 - val_accuracy: 0.8870\nEpoch 39/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2912 - accuracy: 0.8792 - val_loss: 0.2727 - val_accuracy: 0.8905\nEpoch 40/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2881 - accuracy: 0.8811 - val_loss: 0.3010 - val_accuracy: 0.8732\nEpoch 41/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2844 - accuracy: 0.8836 - val_loss: 0.2704 - val_accuracy: 0.8890\nEpoch 42/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2802 - accuracy: 0.8863 - val_loss: 0.2607 - val_accuracy: 0.8946\nEpoch 43/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2818 - accuracy: 0.8840 - val_loss: 0.2648 - val_accuracy: 0.8935\nEpoch 44/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2745 - accuracy: 0.8869 - val_loss: 0.2602 - val_accuracy: 0.8958\nEpoch 45/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2767 - accuracy: 0.8868 - val_loss: 0.2683 - val_accuracy: 0.8919\nEpoch 46/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2721 - accuracy: 0.8889 - val_loss: 0.2650 - val_accuracy: 0.8925\nEpoch 47/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2703 - accuracy: 0.8887 - val_loss: 0.2613 - val_accuracy: 0.8919\nEpoch 48/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.2682 - accuracy: 0.8903 - val_loss: 0.2693 - val_accuracy: 0.8876\nEpoch 49/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2598 - accuracy: 0.8950 - val_loss: 0.2493 - val_accuracy: 0.9002\nEpoch 50/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.2637 - accuracy: 0.8928 - val_loss: 0.2479 - val_accuracy: 0.9015\n"
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Crossentropy - Eucledian - 113x113"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 113, 113, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2t42uros\" target=\"_blank\">giddy-frost-130</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "566/566 [==============================] - 30s 45ms/step - loss: 0.6227 - accuracy: 0.6229 - val_loss: 0.5790 - val_accuracy: 0.6920\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.5223 - accuracy: 0.7389 - val_loss: 0.4835 - val_accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 28s 44ms/step - loss: 0.4869 - accuracy: 0.7681 - val_loss: 0.4635 - val_accuracy: 0.7839\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4713 - accuracy: 0.7746 - val_loss: 0.4926 - val_accuracy: 0.7678\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4629 - accuracy: 0.7806 - val_loss: 0.4713 - val_accuracy: 0.7742\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4506 - accuracy: 0.7885 - val_loss: 0.4416 - val_accuracy: 0.7991\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4512 - accuracy: 0.7875 - val_loss: 0.4446 - val_accuracy: 0.7945\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4241 - accuracy: 0.8086 - val_loss: 0.4128 - val_accuracy: 0.8147\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4150 - accuracy: 0.8127 - val_loss: 0.4133 - val_accuracy: 0.8157\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4094 - accuracy: 0.8151 - val_loss: 0.4053 - val_accuracy: 0.8203\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4051 - accuracy: 0.8176 - val_loss: 0.4044 - val_accuracy: 0.8191\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3983 - accuracy: 0.8227 - val_loss: 0.4022 - val_accuracy: 0.8186\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3944 - accuracy: 0.8244 - val_loss: 0.3834 - val_accuracy: 0.8332\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3877 - accuracy: 0.8282 - val_loss: 0.3790 - val_accuracy: 0.8344\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3881 - accuracy: 0.8274 - val_loss: 0.3827 - val_accuracy: 0.8286\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3790 - accuracy: 0.8325 - val_loss: 0.3781 - val_accuracy: 0.8321\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3809 - accuracy: 0.8311 - val_loss: 0.3765 - val_accuracy: 0.8363\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3777 - accuracy: 0.8321 - val_loss: 0.3772 - val_accuracy: 0.8349\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3770 - accuracy: 0.8342 - val_loss: 0.3816 - val_accuracy: 0.8339\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3709 - accuracy: 0.8372 - val_loss: 0.3696 - val_accuracy: 0.8393\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3702 - accuracy: 0.8382 - val_loss: 0.3574 - val_accuracy: 0.8469\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3664 - accuracy: 0.8410 - val_loss: 0.3525 - val_accuracy: 0.8497\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3532 - accuracy: 0.8485 - val_loss: 0.3574 - val_accuracy: 0.8448\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3493 - accuracy: 0.8504 - val_loss: 0.3565 - val_accuracy: 0.8483\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3436 - accuracy: 0.8527 - val_loss: 0.3373 - val_accuracy: 0.8561\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3437 - accuracy: 0.8517 - val_loss: 0.3346 - val_accuracy: 0.8630\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3399 - accuracy: 0.8553 - val_loss: 0.3224 - val_accuracy: 0.8651\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3398 - accuracy: 0.8544 - val_loss: 0.3543 - val_accuracy: 0.8463\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3325 - accuracy: 0.8590 - val_loss: 0.3188 - val_accuracy: 0.8660\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3339 - accuracy: 0.8585 - val_loss: 0.3335 - val_accuracy: 0.8550\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3290 - accuracy: 0.8596 - val_loss: 0.3148 - val_accuracy: 0.8679\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3228 - accuracy: 0.8633 - val_loss: 0.3285 - val_accuracy: 0.8599\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3276 - accuracy: 0.8624 - val_loss: 0.3320 - val_accuracy: 0.8570\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3190 - accuracy: 0.8663 - val_loss: 0.3120 - val_accuracy: 0.8702\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3176 - accuracy: 0.8661 - val_loss: 0.3603 - val_accuracy: 0.8432\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3165 - accuracy: 0.8660 - val_loss: 0.3081 - val_accuracy: 0.8695\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3118 - accuracy: 0.8683 - val_loss: 0.3288 - val_accuracy: 0.8627\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3133 - accuracy: 0.8691 - val_loss: 0.2988 - val_accuracy: 0.8767\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3114 - accuracy: 0.8697 - val_loss: 0.2998 - val_accuracy: 0.8773\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3066 - accuracy: 0.8728 - val_loss: 0.3064 - val_accuracy: 0.8709\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3079 - accuracy: 0.8714 - val_loss: 0.3253 - val_accuracy: 0.8616\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3051 - accuracy: 0.8724 - val_loss: 0.2861 - val_accuracy: 0.8826\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2990 - accuracy: 0.8750 - val_loss: 0.2903 - val_accuracy: 0.8788\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2981 - accuracy: 0.8754 - val_loss: 0.2976 - val_accuracy: 0.8747\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2950 - accuracy: 0.8780 - val_loss: 0.3015 - val_accuracy: 0.8738\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2941 - accuracy: 0.8786 - val_loss: 0.2801 - val_accuracy: 0.8859\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2926 - accuracy: 0.8792 - val_loss: 0.2958 - val_accuracy: 0.8799\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2880 - accuracy: 0.8807 - val_loss: 0.2892 - val_accuracy: 0.8822\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2865 - accuracy: 0.8826 - val_loss: 0.2730 - val_accuracy: 0.8911\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2876 - accuracy: 0.8815 - val_loss: 0.3112 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Manhatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/o7vtpkvj\" target=\"_blank\">helpful-dust-103</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n286/286 [==============================] - 97s 256ms/step - loss: 0.2150 - accuracy: 0.6027 - val_loss: 0.2088 - val_accuracy: 0.7130\nEpoch 2/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1919 - accuracy: 0.7129 - val_loss: 0.1750 - val_accuracy: 0.7641\nEpoch 3/50\n286/286 [==============================] - 75s 242ms/step - loss: 0.1748 - accuracy: 0.7571 - val_loss: 0.1712 - val_accuracy: 0.7856\nEpoch 4/50\n286/286 [==============================] - 75s 244ms/step - loss: 0.1651 - accuracy: 0.7747 - val_loss: 0.1654 - val_accuracy: 0.7944\nEpoch 5/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1601 - accuracy: 0.7827 - val_loss: 0.1576 - val_accuracy: 0.7927\nEpoch 6/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1539 - accuracy: 0.7932 - val_loss: 0.1497 - val_accuracy: 0.7985\nEpoch 7/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1450 - accuracy: 0.8072 - val_loss: 0.1417 - val_accuracy: 0.8181\nEpoch 8/50\n286/286 [==============================] - 75s 243ms/step - loss: 0.1384 - accuracy: 0.8173 - val_loss: 0.1387 - val_accuracy: 0.8178\nEpoch 9/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1344 - accuracy: 0.8206 - val_loss: 0.1300 - val_accuracy: 0.8312\nEpoch 10/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1306 - accuracy: 0.8271 - val_loss: 0.1309 - val_accuracy: 0.8269\nEpoch 11/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1274 - accuracy: 0.8318 - val_loss: 0.1274 - val_accuracy: 0.8359\nEpoch 12/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1231 - accuracy: 0.8382 - val_loss: 0.1188 - val_accuracy: 0.8437\nEpoch 13/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1196 - accuracy: 0.8420 - val_loss: 0.1208 - val_accuracy: 0.8383\nEpoch 14/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1185 - accuracy: 0.8423 - val_loss: 0.1159 - val_accuracy: 0.8454\nEpoch 15/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1169 - accuracy: 0.8431 - val_loss: 0.1101 - val_accuracy: 0.8572\nEpoch 16/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1129 - accuracy: 0.8507 - val_loss: 0.1077 - val_accuracy: 0.8600\nEpoch 17/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1117 - accuracy: 0.8518 - val_loss: 0.1108 - val_accuracy: 0.8489\nEpoch 18/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1119 - accuracy: 0.8498 - val_loss: 0.1088 - val_accuracy: 0.8554\nEpoch 19/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1097 - accuracy: 0.8528 - val_loss: 0.1063 - val_accuracy: 0.8607\nEpoch 20/50\n286/286 [==============================] - 74s 241ms/step - loss: 0.1098 - accuracy: 0.8529 - val_loss: 0.1115 - val_accuracy: 0.8483\nEpoch 21/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1082 - accuracy: 0.8554 - val_loss: 0.1119 - val_accuracy: 0.8506\nEpoch 22/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1071 - accuracy: 0.8561 - val_loss: 0.1023 - val_accuracy: 0.8616\nEpoch 23/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1056 - accuracy: 0.8593 - val_loss: 0.1071 - val_accuracy: 0.8577\nEpoch 24/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1035 - accuracy: 0.8620 - val_loss: 0.1003 - val_accuracy: 0.8680\nEpoch 25/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1033 - accuracy: 0.8616 - val_loss: 0.1046 - val_accuracy: 0.8594\nEpoch 26/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.1023 - accuracy: 0.8635 - val_loss: 0.1080 - val_accuracy: 0.8551\nEpoch 27/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1017 - accuracy: 0.8645 - val_loss: 0.0983 - val_accuracy: 0.8677\nEpoch 28/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0998 - accuracy: 0.8665 - val_loss: 0.0998 - val_accuracy: 0.8692\nEpoch 29/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.1017 - accuracy: 0.8639 - val_loss: 0.0989 - val_accuracy: 0.8676\nEpoch 30/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0996 - accuracy: 0.8679 - val_loss: 0.1036 - val_accuracy: 0.8611\nEpoch 31/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0993 - accuracy: 0.8678 - val_loss: 0.1087 - val_accuracy: 0.8540\nEpoch 32/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0979 - accuracy: 0.8691 - val_loss: 0.0938 - val_accuracy: 0.8756\nEpoch 33/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0970 - accuracy: 0.8723 - val_loss: 0.0956 - val_accuracy: 0.8715\nEpoch 34/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0966 - accuracy: 0.8710 - val_loss: 0.0945 - val_accuracy: 0.8738\nEpoch 35/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0965 - accuracy: 0.8710 - val_loss: 0.0970 - val_accuracy: 0.8720\nEpoch 36/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0955 - accuracy: 0.8734 - val_loss: 0.0964 - val_accuracy: 0.8723\nEpoch 37/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0945 - accuracy: 0.8740 - val_loss: 0.0891 - val_accuracy: 0.8850\nEpoch 38/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0914 - accuracy: 0.8788 - val_loss: 0.0947 - val_accuracy: 0.8722\nEpoch 39/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0919 - accuracy: 0.8776 - val_loss: 0.0880 - val_accuracy: 0.8839\nEpoch 40/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0920 - accuracy: 0.8775 - val_loss: 0.0895 - val_accuracy: 0.8791\nEpoch 41/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0906 - accuracy: 0.8805 - val_loss: 0.0912 - val_accuracy: 0.8772\nEpoch 42/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0887 - accuracy: 0.8822 - val_loss: 0.0820 - val_accuracy: 0.8930\nEpoch 43/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0878 - accuracy: 0.8848 - val_loss: 0.0827 - val_accuracy: 0.8924\nEpoch 44/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0872 - accuracy: 0.8859 - val_loss: 0.0833 - val_accuracy: 0.8922\nEpoch 45/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0862 - accuracy: 0.8866 - val_loss: 0.0824 - val_accuracy: 0.8954\nEpoch 46/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0854 - accuracy: 0.8874 - val_loss: 0.0878 - val_accuracy: 0.8849\nEpoch 47/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0858 - accuracy: 0.8867 - val_loss: 0.0823 - val_accuracy: 0.8927\nEpoch 48/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0777 - accuracy: 0.8995 - val_loss: 0.0767 - val_accuracy: 0.9031\nEpoch 49/50\n286/286 [==============================] - 74s 243ms/step - loss: 0.0766 - accuracy: 0.9019 - val_loss: 0.0766 - val_accuracy: 0.9022\nEpoch 50/50\n286/286 [==============================] - 74s 242ms/step - loss: 0.0753 - accuracy: 0.9041 - val_loss: 0.0762 - val_accuracy: 0.9020\n"
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(manhattan_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Contrastive - Manhatten - 113x113"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 113, 113, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "566/566 [==============================] - 47s 48ms/step - loss: 0.2167 - accuracy: 0.6303 - val_loss: 0.1840 - val_accuracy: 0.7322\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 32s 48ms/step - loss: 0.1761 - accuracy: 0.7545 - val_loss: 0.1657 - val_accuracy: 0.7848\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1647 - accuracy: 0.7720 - val_loss: 0.1653 - val_accuracy: 0.7675\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1512 - accuracy: 0.7938 - val_loss: 0.1451 - val_accuracy: 0.8068\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1458 - accuracy: 0.8009 - val_loss: 0.1428 - val_accuracy: 0.8083\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 32s 48ms/step - loss: 0.1423 - accuracy: 0.8032 - val_loss: 0.1345 - val_accuracy: 0.8194\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1369 - accuracy: 0.8110 - val_loss: 0.1343 - val_accuracy: 0.8149\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1367 - accuracy: 0.8102 - val_loss: 0.1309 - val_accuracy: 0.8201\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1313 - accuracy: 0.8198 - val_loss: 0.1316 - val_accuracy: 0.8191\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1255 - accuracy: 0.8293 - val_loss: 0.1235 - val_accuracy: 0.8329\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1243 - accuracy: 0.8305 - val_loss: 0.1447 - val_accuracy: 0.7943\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1278 - accuracy: 0.8233 - val_loss: 0.1240 - val_accuracy: 0.8271\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1217 - accuracy: 0.8327 - val_loss: 0.1181 - val_accuracy: 0.8399\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1177 - accuracy: 0.8399 - val_loss: 0.1151 - val_accuracy: 0.8461\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1151 - accuracy: 0.8440 - val_loss: 0.1094 - val_accuracy: 0.8533\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 32s 47ms/step - loss: 0.1130 - accuracy: 0.8467 - val_loss: 0.1160 - val_accuracy: 0.8403\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1116 - accuracy: 0.8489 - val_loss: 0.1108 - val_accuracy: 0.8494\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1103 - accuracy: 0.8517 - val_loss: 0.1094 - val_accuracy: 0.8520\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1100 - accuracy: 0.8521 - val_loss: 0.1095 - val_accuracy: 0.8495\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1086 - accuracy: 0.8537 - val_loss: 0.1059 - val_accuracy: 0.8588\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1074 - accuracy: 0.8561 - val_loss: 0.1012 - val_accuracy: 0.8670\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1070 - accuracy: 0.8560 - val_loss: 0.1114 - val_accuracy: 0.8476\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1073 - accuracy: 0.8556 - val_loss: 0.1027 - val_accuracy: 0.8623\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1047 - accuracy: 0.8592 - val_loss: 0.1101 - val_accuracy: 0.8525\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1037 - accuracy: 0.8622 - val_loss: 0.1009 - val_accuracy: 0.8653\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1027 - accuracy: 0.8624 - val_loss: 0.0958 - val_accuracy: 0.8732\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1027 - accuracy: 0.8619 - val_loss: 0.1037 - val_accuracy: 0.8591\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1028 - accuracy: 0.8622 - val_loss: 0.0972 - val_accuracy: 0.8708\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1009 - accuracy: 0.8656 - val_loss: 0.1007 - val_accuracy: 0.8679\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.1008 - accuracy: 0.8647 - val_loss: 0.0999 - val_accuracy: 0.8652\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.1006 - accuracy: 0.8656 - val_loss: 0.1020 - val_accuracy: 0.8626\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.0927 - accuracy: 0.8781 - val_loss: 0.0934 - val_accuracy: 0.8796\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.0907 - accuracy: 0.8804 - val_loss: 0.0892 - val_accuracy: 0.8842\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0899 - accuracy: 0.8821 - val_loss: 0.0897 - val_accuracy: 0.8818\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.0899 - accuracy: 0.8816 - val_loss: 0.0895 - val_accuracy: 0.8827\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 31s 47ms/step - loss: 0.0894 - accuracy: 0.8823 - val_loss: 0.0878 - val_accuracy: 0.8855\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0884 - accuracy: 0.8843 - val_loss: 0.0875 - val_accuracy: 0.8837\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0884 - accuracy: 0.8837 - val_loss: 0.0885 - val_accuracy: 0.8838\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0878 - accuracy: 0.8846 - val_loss: 0.0864 - val_accuracy: 0.8875\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.0880 - accuracy: 0.8848 - val_loss: 0.0876 - val_accuracy: 0.8853\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 31s 46ms/step - loss: 0.0875 - accuracy: 0.8850 - val_loss: 0.0872 - val_accuracy: 0.8857\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0876 - accuracy: 0.8858 - val_loss: 0.0864 - val_accuracy: 0.8876\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0867 - accuracy: 0.8869 - val_loss: 0.0845 - val_accuracy: 0.8899\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0861 - accuracy: 0.8877 - val_loss: 0.0872 - val_accuracy: 0.8854\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0866 - accuracy: 0.8874 - val_loss: 0.0834 - val_accuracy: 0.8909\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0854 - accuracy: 0.8892 - val_loss: 0.0877 - val_accuracy: 0.8877\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0858 - accuracy: 0.8885 - val_loss: 0.0854 - val_accuracy: 0.8903\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0850 - accuracy: 0.8892 - val_loss: 0.0832 - val_accuracy: 0.8920\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0847 - accuracy: 0.8888 - val_loss: 0.0870 - val_accuracy: 0.8862\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 30s 46ms/step - loss: 0.0850 - accuracy: 0.8895 - val_loss: 0.0840 - val_accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(manhattan_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Crossentropy - Manhatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/v8m285cf\" target=\"_blank\">pretty-sponge-116</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 97s 256ms/step - loss: 0.6227 - accuracy: 0.5844 - val_loss: 0.5763 - val_accuracy: 0.6762\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.5571 - accuracy: 0.6950 - val_loss: 0.5226 - val_accuracy: 0.7384\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.5276 - accuracy: 0.7367 - val_loss: 0.5191 - val_accuracy: 0.7504\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.5036 - accuracy: 0.7560 - val_loss: 0.4937 - val_accuracy: 0.7837\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.4895 - accuracy: 0.7692 - val_loss: 0.4737 - val_accuracy: 0.7750\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4677 - accuracy: 0.7854 - val_loss: 0.4644 - val_accuracy: 0.7825\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4558 - accuracy: 0.7945 - val_loss: 0.4332 - val_accuracy: 0.8137\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.4405 - accuracy: 0.8026 - val_loss: 0.4430 - val_accuracy: 0.8089\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4333 - accuracy: 0.8050 - val_loss: 0.4214 - val_accuracy: 0.8109\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4240 - accuracy: 0.8093 - val_loss: 0.4200 - val_accuracy: 0.8186\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4167 - accuracy: 0.8133 - val_loss: 0.4177 - val_accuracy: 0.8117\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4095 - accuracy: 0.8169 - val_loss: 0.4473 - val_accuracy: 0.7946\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.4112 - accuracy: 0.8166 - val_loss: 0.4135 - val_accuracy: 0.8130\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4070 - accuracy: 0.8181 - val_loss: 0.4117 - val_accuracy: 0.8186\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3950 - accuracy: 0.8257 - val_loss: 0.3894 - val_accuracy: 0.8300\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3864 - accuracy: 0.8287 - val_loss: 0.3938 - val_accuracy: 0.8266\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3829 - accuracy: 0.8308 - val_loss: 0.3706 - val_accuracy: 0.8344\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 75s 245ms/step - loss: 0.3820 - accuracy: 0.8304 - val_loss: 0.3671 - val_accuracy: 0.8391\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3764 - accuracy: 0.8355 - val_loss: 0.3783 - val_accuracy: 0.8315\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3740 - accuracy: 0.8353 - val_loss: 0.3790 - val_accuracy: 0.8337\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3685 - accuracy: 0.8384 - val_loss: 0.3597 - val_accuracy: 0.8409\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3668 - accuracy: 0.8394 - val_loss: 0.3548 - val_accuracy: 0.8476\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.3669 - accuracy: 0.8388 - val_loss: 0.3678 - val_accuracy: 0.8383\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3614 - accuracy: 0.8410 - val_loss: 0.3491 - val_accuracy: 0.8444\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3545 - accuracy: 0.8455 - val_loss: 0.3447 - val_accuracy: 0.8515\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3509 - accuracy: 0.8473 - val_loss: 0.3429 - val_accuracy: 0.8544\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3471 - accuracy: 0.8504 - val_loss: 0.3322 - val_accuracy: 0.8602\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3417 - accuracy: 0.8534 - val_loss: 0.3277 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3377 - accuracy: 0.8534 - val_loss: 0.3287 - val_accuracy: 0.8615\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.3437 - accuracy: 0.8504 - val_loss: 0.3272 - val_accuracy: 0.8592\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3352 - accuracy: 0.8554 - val_loss: 0.3244 - val_accuracy: 0.8625\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3315 - accuracy: 0.8570 - val_loss: 0.3243 - val_accuracy: 0.8595\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3277 - accuracy: 0.8597 - val_loss: 0.3310 - val_accuracy: 0.8588\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3260 - accuracy: 0.8607 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3278 - accuracy: 0.8584 - val_loss: 0.3319 - val_accuracy: 0.8555\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3236 - accuracy: 0.8606 - val_loss: 0.3174 - val_accuracy: 0.8669\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3207 - accuracy: 0.8633 - val_loss: 0.3054 - val_accuracy: 0.8738\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3184 - accuracy: 0.8640 - val_loss: 0.2986 - val_accuracy: 0.8730\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.3125 - accuracy: 0.8661 - val_loss: 0.3206 - val_accuracy: 0.8653\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.3157 - accuracy: 0.8661 - val_loss: 0.3173 - val_accuracy: 0.8609\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.3142 - accuracy: 0.8653 - val_loss: 0.3084 - val_accuracy: 0.8677\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3110 - accuracy: 0.8676 - val_loss: 0.2975 - val_accuracy: 0.8734\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.3021 - accuracy: 0.8723 - val_loss: 0.2943 - val_accuracy: 0.8750\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3102 - accuracy: 0.8673 - val_loss: 0.3076 - val_accuracy: 0.8695\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3099 - accuracy: 0.8680 - val_loss: 0.2925 - val_accuracy: 0.8767\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3050 - accuracy: 0.8697 - val_loss: 0.3078 - val_accuracy: 0.8698\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3018 - accuracy: 0.8719 - val_loss: 0.3184 - val_accuracy: 0.8629\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.2988 - accuracy: 0.8731 - val_loss: 0.2863 - val_accuracy: 0.8796\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2952 - accuracy: 0.8730 - val_loss: 0.2834 - val_accuracy: 0.8807\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2946 - accuracy: 0.8740 - val_loss: 0.3079 - val_accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(manhattan_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 90K - RGB - Crossentropy - Manhatten - 113x113"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 113, 113, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "566/566 [==============================] - 30s 45ms/step - loss: 0.6406 - accuracy: 0.6034 - val_loss: 0.6784 - val_accuracy: 0.6095\n",
      "Epoch 2/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.5880 - accuracy: 0.6972 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 3/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.5260 - accuracy: 0.7413 - val_loss: 0.5030 - val_accuracy: 0.7598\n",
      "Epoch 4/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.4711 - accuracy: 0.7815 - val_loss: 0.4733 - val_accuracy: 0.7677\n",
      "Epoch 5/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4577 - accuracy: 0.7875 - val_loss: 0.4940 - val_accuracy: 0.7740\n",
      "Epoch 6/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4378 - accuracy: 0.7999 - val_loss: 0.4317 - val_accuracy: 0.8021\n",
      "Epoch 7/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.4232 - accuracy: 0.8076 - val_loss: 0.4299 - val_accuracy: 0.8059\n",
      "Epoch 8/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4135 - accuracy: 0.8125 - val_loss: 0.4112 - val_accuracy: 0.8129\n",
      "Epoch 9/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.4073 - accuracy: 0.8163 - val_loss: 0.3949 - val_accuracy: 0.8222\n",
      "Epoch 10/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3948 - accuracy: 0.8239 - val_loss: 0.3713 - val_accuracy: 0.8397\n",
      "Epoch 11/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3839 - accuracy: 0.8305 - val_loss: 0.3948 - val_accuracy: 0.8238\n",
      "Epoch 12/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3845 - accuracy: 0.8306 - val_loss: 0.4972 - val_accuracy: 0.7530\n",
      "Epoch 13/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3712 - accuracy: 0.8382 - val_loss: 0.3741 - val_accuracy: 0.8388\n",
      "Epoch 14/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3621 - accuracy: 0.8431 - val_loss: 0.3631 - val_accuracy: 0.8413\n",
      "Epoch 15/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3599 - accuracy: 0.8446 - val_loss: 0.3769 - val_accuracy: 0.8321\n",
      "Epoch 16/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3576 - accuracy: 0.8454 - val_loss: 0.3704 - val_accuracy: 0.8392\n",
      "Epoch 17/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3601 - accuracy: 0.8431 - val_loss: 0.3699 - val_accuracy: 0.8388\n",
      "Epoch 18/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3489 - accuracy: 0.8494 - val_loss: 0.3566 - val_accuracy: 0.8464\n",
      "Epoch 19/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3455 - accuracy: 0.8519 - val_loss: 0.3378 - val_accuracy: 0.8570\n",
      "Epoch 20/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3467 - accuracy: 0.8500 - val_loss: 0.3364 - val_accuracy: 0.8557\n",
      "Epoch 21/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3400 - accuracy: 0.8539 - val_loss: 0.3334 - val_accuracy: 0.8565\n",
      "Epoch 22/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3347 - accuracy: 0.8577 - val_loss: 0.3472 - val_accuracy: 0.8469\n",
      "Epoch 23/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3299 - accuracy: 0.8599 - val_loss: 0.3072 - val_accuracy: 0.8727\n",
      "Epoch 24/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3328 - accuracy: 0.8575 - val_loss: 0.3372 - val_accuracy: 0.8515\n",
      "Epoch 25/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3268 - accuracy: 0.8610 - val_loss: 0.3056 - val_accuracy: 0.8708\n",
      "Epoch 26/50\n",
      "566/566 [==============================] - 28s 44ms/step - loss: 0.3212 - accuracy: 0.8649 - val_loss: 0.3130 - val_accuracy: 0.8697\n",
      "Epoch 27/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3179 - accuracy: 0.8651 - val_loss: 0.3180 - val_accuracy: 0.8655\n",
      "Epoch 28/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3171 - accuracy: 0.8652 - val_loss: 0.3147 - val_accuracy: 0.8674\n",
      "Epoch 29/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.3082 - accuracy: 0.8710 - val_loss: 0.3276 - val_accuracy: 0.8570\n",
      "Epoch 30/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.3109 - accuracy: 0.8687 - val_loss: 0.3091 - val_accuracy: 0.8692\n",
      "Epoch 31/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2858 - accuracy: 0.8842 - val_loss: 0.2804 - val_accuracy: 0.8862\n",
      "Epoch 32/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.2820 - accuracy: 0.8862 - val_loss: 0.2759 - val_accuracy: 0.8884\n",
      "Epoch 33/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2805 - accuracy: 0.8866 - val_loss: 0.2819 - val_accuracy: 0.8859\n",
      "Epoch 34/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.2808 - accuracy: 0.8861 - val_loss: 0.2879 - val_accuracy: 0.8813\n",
      "Epoch 35/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2789 - accuracy: 0.8880 - val_loss: 0.2777 - val_accuracy: 0.8882\n",
      "Epoch 36/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.2783 - accuracy: 0.8874 - val_loss: 0.2779 - val_accuracy: 0.8854\n",
      "Epoch 37/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2747 - accuracy: 0.8903 - val_loss: 0.2740 - val_accuracy: 0.8885\n",
      "Epoch 38/50\n",
      "566/566 [==============================] - 29s 44ms/step - loss: 0.2755 - accuracy: 0.8891 - val_loss: 0.2688 - val_accuracy: 0.8917\n",
      "Epoch 39/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2763 - accuracy: 0.8894 - val_loss: 0.2719 - val_accuracy: 0.8905\n",
      "Epoch 40/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2742 - accuracy: 0.8896 - val_loss: 0.2685 - val_accuracy: 0.8946\n",
      "Epoch 41/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2736 - accuracy: 0.8898 - val_loss: 0.2666 - val_accuracy: 0.8920\n",
      "Epoch 42/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2730 - accuracy: 0.8905 - val_loss: 0.2758 - val_accuracy: 0.8880\n",
      "Epoch 43/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2726 - accuracy: 0.8899 - val_loss: 0.2708 - val_accuracy: 0.8908\n",
      "Epoch 44/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2713 - accuracy: 0.8915 - val_loss: 0.2745 - val_accuracy: 0.8882\n",
      "Epoch 45/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2729 - accuracy: 0.8907 - val_loss: 0.2740 - val_accuracy: 0.8892\n",
      "Epoch 46/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2690 - accuracy: 0.8918 - val_loss: 0.2707 - val_accuracy: 0.8917\n",
      "Epoch 47/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2675 - accuracy: 0.8932 - val_loss: 0.2708 - val_accuracy: 0.8912\n",
      "Epoch 48/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2662 - accuracy: 0.8937 - val_loss: 0.2671 - val_accuracy: 0.8925\n",
      "Epoch 49/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2667 - accuracy: 0.8929 - val_loss: 0.2656 - val_accuracy: 0.8943\n",
      "Epoch 50/50\n",
      "566/566 [==============================] - 29s 45ms/step - loss: 0.2657 - accuracy: 0.8933 - val_loss: 0.2639 - val_accuracy: 0.8962\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(manhattan_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}