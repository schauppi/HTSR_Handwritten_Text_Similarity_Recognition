{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from helper_functions import get_classification_report\n",
    "from helper_functions import create_tf_data_datasets_contrastive\n",
    "from helper_functions import create_tf_data_testset_contrastive\n",
    "from helper_functions import euclidean_distance\n",
    "from helper_functions import contrastive_loss\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras import mixed_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def AlexNet(height, width, channels):\n",
    "\n",
    "    X_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    X = keras.layers.Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 ,name='bn1')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn4')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
    "\n",
    "    X = keras.layers.Flatten()(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'sigmoid', name = 'fc1')(X)\n",
    "\n",
    "    model = keras.models.Model(inputs = X_input, outputs = X, name='AlexNet')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def half_deep_writer(height, width, channels):\n",
    "\n",
    "    input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    x = keras.layers.Conv2D(96, kernel_size=5, strides=2, activation='relu')(input)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\",  activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "    output = keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "    model = keras.models.Model(input, output)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alexnet - 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2330cufh\" target=\"_blank\">clear-paper-82</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 69s 180ms/step - loss: 0.2205 - accuracy: 0.6626 - val_loss: 0.2291 - val_accuracy: 0.6202\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2128 - accuracy: 0.6694 - val_loss: 0.2588 - val_accuracy: 0.5252\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2090 - accuracy: 0.6741 - val_loss: 0.2761 - val_accuracy: 0.6213\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2152 - accuracy: 0.6686 - val_loss: 0.2653 - val_accuracy: 0.4989\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2157 - accuracy: 0.6663 - val_loss: 0.2749 - val_accuracy: 0.5853\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2092 - accuracy: 0.6758 - val_loss: 0.2726 - val_accuracy: 0.5025\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2087 - accuracy: 0.6708 - val_loss: 0.2078 - val_accuracy: 0.6689\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2054 - accuracy: 0.6774 - val_loss: 0.2029 - val_accuracy: 0.6791\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2022 - accuracy: 0.6809 - val_loss: 0.1983 - val_accuracy: 0.6876\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2015 - accuracy: 0.6804 - val_loss: 0.2001 - val_accuracy: 0.6796\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1991 - accuracy: 0.6841 - val_loss: 0.2000 - val_accuracy: 0.6770\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1979 - accuracy: 0.6852 - val_loss: 0.2016 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1983 - accuracy: 0.6830 - val_loss: 0.1963 - val_accuracy: 0.6863\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1978 - accuracy: 0.6815 - val_loss: 0.1982 - val_accuracy: 0.6769\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1976 - accuracy: 0.6835 - val_loss: 0.1962 - val_accuracy: 0.6848\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1956 - accuracy: 0.6835 - val_loss: 0.2098 - val_accuracy: 0.6811\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1961 - accuracy: 0.6827 - val_loss: 0.2010 - val_accuracy: 0.6744\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1945 - accuracy: 0.6847 - val_loss: 0.1929 - val_accuracy: 0.6828\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1940 - accuracy: 0.6845 - val_loss: 0.1915 - val_accuracy: 0.6885\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1927 - accuracy: 0.6970 - val_loss: 0.2014 - val_accuracy: 0.6873\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1915 - accuracy: 0.7153 - val_loss: 0.1940 - val_accuracy: 0.7085\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1914 - accuracy: 0.7144 - val_loss: 0.1889 - val_accuracy: 0.7209\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1899 - accuracy: 0.7181 - val_loss: 0.2192 - val_accuracy: 0.6637\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1896 - accuracy: 0.7192 - val_loss: 0.1880 - val_accuracy: 0.7184\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1890 - accuracy: 0.7184 - val_loss: 0.1887 - val_accuracy: 0.7182\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1878 - accuracy: 0.7243 - val_loss: 0.1890 - val_accuracy: 0.7204\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1869 - accuracy: 0.7266 - val_loss: 0.1876 - val_accuracy: 0.7314\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1848 - accuracy: 0.7314 - val_loss: 0.1871 - val_accuracy: 0.7230\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1839 - accuracy: 0.7327 - val_loss: 0.1829 - val_accuracy: 0.7376\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1843 - accuracy: 0.7338 - val_loss: 0.1847 - val_accuracy: 0.7294\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1823 - accuracy: 0.7381 - val_loss: 0.1776 - val_accuracy: 0.7461\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1803 - accuracy: 0.7425 - val_loss: 0.1788 - val_accuracy: 0.7421\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1798 - accuracy: 0.7403 - val_loss: 0.1768 - val_accuracy: 0.7455\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1776 - accuracy: 0.7448 - val_loss: 0.1844 - val_accuracy: 0.7277\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1742 - accuracy: 0.7555 - val_loss: 0.1915 - val_accuracy: 0.7032\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1716 - accuracy: 0.7589 - val_loss: 0.1761 - val_accuracy: 0.7428\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1720 - accuracy: 0.7583 - val_loss: 0.1888 - val_accuracy: 0.7394\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1673 - accuracy: 0.7673 - val_loss: 0.1803 - val_accuracy: 0.7455\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1623 - accuracy: 0.7781 - val_loss: 0.1721 - val_accuracy: 0.7663\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1593 - accuracy: 0.7829 - val_loss: 0.1614 - val_accuracy: 0.7816\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1568 - accuracy: 0.7930 - val_loss: 0.1592 - val_accuracy: 0.7950\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1550 - accuracy: 0.7947 - val_loss: 0.1583 - val_accuracy: 0.7922\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1548 - accuracy: 0.7950 - val_loss: 0.1633 - val_accuracy: 0.7671\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1522 - accuracy: 0.7995 - val_loss: 0.1755 - val_accuracy: 0.7661\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1520 - accuracy: 0.8014 - val_loss: 0.1831 - val_accuracy: 0.7432\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1509 - accuracy: 0.8059 - val_loss: 0.1949 - val_accuracy: 0.6898\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1495 - accuracy: 0.8064 - val_loss: 0.1752 - val_accuracy: 0.7414\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1470 - accuracy: 0.8127 - val_loss: 0.1487 - val_accuracy: 0.8140\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1471 - accuracy: 0.8141 - val_loss: 0.1475 - val_accuracy: 0.8105\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1459 - accuracy: 0.8147 - val_loss: 0.1437 - val_accuracy: 0.8192\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alexnet - 90K - RGB - Crossentropy - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/1ejxvo4k\" target=\"_blank\">stoic-haze-95</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 64s 178ms/step - loss: 0.6133 - accuracy: 0.6622 - val_loss: 0.7534 - val_accuracy: 0.6017\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5912 - accuracy: 0.6770 - val_loss: 0.6438 - val_accuracy: 0.6420\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5834 - accuracy: 0.6811 - val_loss: 0.7140 - val_accuracy: 0.6462\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5781 - accuracy: 0.6823 - val_loss: 0.5918 - val_accuracy: 0.6795\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5737 - accuracy: 0.6861 - val_loss: 0.6932 - val_accuracy: 0.5934\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 55s 173ms/step - loss: 0.5690 - accuracy: 0.6855 - val_loss: 0.5794 - val_accuracy: 0.6777\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5711 - accuracy: 0.6849 - val_loss: 0.7822 - val_accuracy: 0.5380\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5715 - accuracy: 0.6863 - val_loss: 0.7446 - val_accuracy: 0.5028\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5691 - accuracy: 0.6868 - val_loss: 0.7219 - val_accuracy: 0.6485\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5648 - accuracy: 0.6893 - val_loss: 0.5568 - val_accuracy: 0.6975\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 55s 173ms/step - loss: 0.5636 - accuracy: 0.6883 - val_loss: 0.5581 - val_accuracy: 0.6888\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5641 - accuracy: 0.6895 - val_loss: 0.5729 - val_accuracy: 0.6796\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5647 - accuracy: 0.6867 - val_loss: 0.7354 - val_accuracy: 0.5094\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5597 - accuracy: 0.6886 - val_loss: 0.9326 - val_accuracy: 0.5229\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5527 - accuracy: 0.6924 - val_loss: 0.5531 - val_accuracy: 0.6914\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5457 - accuracy: 0.7073 - val_loss: 0.7383 - val_accuracy: 0.5953\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 54s 174ms/step - loss: 0.5391 - accuracy: 0.7295 - val_loss: 0.7500 - val_accuracy: 0.6538\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5501 - accuracy: 0.7136 - val_loss: 0.5897 - val_accuracy: 0.6815\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5361 - accuracy: 0.7335 - val_loss: 0.5916 - val_accuracy: 0.6785\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5196 - accuracy: 0.7453 - val_loss: 0.6354 - val_accuracy: 0.7070\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.5076 - accuracy: 0.7534 - val_loss: 0.4974 - val_accuracy: 0.7621\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.5014 - accuracy: 0.7588 - val_loss: 0.5055 - val_accuracy: 0.7495\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4985 - accuracy: 0.7620 - val_loss: 0.5303 - val_accuracy: 0.7486\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4967 - accuracy: 0.7642 - val_loss: 0.4959 - val_accuracy: 0.7596\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4946 - accuracy: 0.7645 - val_loss: 0.4977 - val_accuracy: 0.7627\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4928 - accuracy: 0.7650 - val_loss: 0.4963 - val_accuracy: 0.7633\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4929 - accuracy: 0.7655 - val_loss: 0.4906 - val_accuracy: 0.7657\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4942 - accuracy: 0.7647 - val_loss: 0.4911 - val_accuracy: 0.7688\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4897 - accuracy: 0.7678 - val_loss: 0.4935 - val_accuracy: 0.7596\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4863 - accuracy: 0.7682 - val_loss: 0.4893 - val_accuracy: 0.7657\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4889 - accuracy: 0.7668 - val_loss: 0.4914 - val_accuracy: 0.7659\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4865 - accuracy: 0.7680 - val_loss: 0.5017 - val_accuracy: 0.7631\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4846 - accuracy: 0.7703 - val_loss: 0.4976 - val_accuracy: 0.7641\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4837 - accuracy: 0.7718 - val_loss: 0.4816 - val_accuracy: 0.7730\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 54s 174ms/step - loss: 0.4827 - accuracy: 0.7720 - val_loss: 0.4896 - val_accuracy: 0.7697\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4844 - accuracy: 0.7706 - val_loss: 0.4831 - val_accuracy: 0.7661\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4803 - accuracy: 0.7734 - val_loss: 0.4800 - val_accuracy: 0.7696\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4787 - accuracy: 0.7733 - val_loss: 0.4765 - val_accuracy: 0.7706\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4778 - accuracy: 0.7744 - val_loss: 0.5210 - val_accuracy: 0.7523\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4754 - accuracy: 0.7750 - val_loss: 0.4761 - val_accuracy: 0.7755\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4725 - accuracy: 0.7765 - val_loss: 0.5047 - val_accuracy: 0.7658\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4710 - accuracy: 0.7773 - val_loss: 0.4691 - val_accuracy: 0.7759\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4688 - accuracy: 0.7777 - val_loss: 0.4657 - val_accuracy: 0.7862\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 54s 174ms/step - loss: 0.4667 - accuracy: 0.7832 - val_loss: 0.4804 - val_accuracy: 0.7755\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4628 - accuracy: 0.7834 - val_loss: 0.4885 - val_accuracy: 0.7709\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 54s 174ms/step - loss: 0.4591 - accuracy: 0.7937 - val_loss: 0.4623 - val_accuracy: 0.7940\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 55s 174ms/step - loss: 0.4586 - accuracy: 0.7958 - val_loss: 0.4633 - val_accuracy: 0.7930\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4559 - accuracy: 0.7991 - val_loss: 0.5042 - val_accuracy: 0.7501\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4540 - accuracy: 0.8014 - val_loss: 0.4574 - val_accuracy: 0.7974\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 54s 173ms/step - loss: 0.4538 - accuracy: 0.8029 - val_loss: 0.4668 - val_accuracy: 0.7977\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Half DeepWriter - 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/3qa9jwgq\" target=\"_blank\">major-water-79</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 95s 255ms/step - loss: 0.2202 - accuracy: 0.5964 - val_loss: 0.2030 - val_accuracy: 0.6824\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.1987 - accuracy: 0.7048 - val_loss: 0.1860 - val_accuracy: 0.7404\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1810 - accuracy: 0.7480 - val_loss: 0.1754 - val_accuracy: 0.7636\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1695 - accuracy: 0.7690 - val_loss: 0.1634 - val_accuracy: 0.7850\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1624 - accuracy: 0.7792 - val_loss: 0.1557 - val_accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1552 - accuracy: 0.7925 - val_loss: 0.1533 - val_accuracy: 0.7907\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1479 - accuracy: 0.8036 - val_loss: 0.1399 - val_accuracy: 0.8239\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.1416 - accuracy: 0.8117 - val_loss: 0.1412 - val_accuracy: 0.8131\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1354 - accuracy: 0.8206 - val_loss: 0.1322 - val_accuracy: 0.8242\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1318 - accuracy: 0.8254 - val_loss: 0.1289 - val_accuracy: 0.8316\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1326 - accuracy: 0.8225 - val_loss: 0.1515 - val_accuracy: 0.7873\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1404 - accuracy: 0.8052 - val_loss: 0.1226 - val_accuracy: 0.8380\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1275 - accuracy: 0.8279 - val_loss: 0.1219 - val_accuracy: 0.8376\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1215 - accuracy: 0.8372 - val_loss: 0.1148 - val_accuracy: 0.8485\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1192 - accuracy: 0.8406 - val_loss: 0.1165 - val_accuracy: 0.8438\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1165 - accuracy: 0.8447 - val_loss: 0.1126 - val_accuracy: 0.8506\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1133 - accuracy: 0.8503 - val_loss: 0.1162 - val_accuracy: 0.8402\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1110 - accuracy: 0.8530 - val_loss: 0.1097 - val_accuracy: 0.8538\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1079 - accuracy: 0.8581 - val_loss: 0.1058 - val_accuracy: 0.8606\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1069 - accuracy: 0.8585 - val_loss: 0.1048 - val_accuracy: 0.8635\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1060 - accuracy: 0.8582 - val_loss: 0.1006 - val_accuracy: 0.8680\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1050 - accuracy: 0.8612 - val_loss: 0.1041 - val_accuracy: 0.8618\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1019 - accuracy: 0.8646 - val_loss: 0.0987 - val_accuracy: 0.8712\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1024 - accuracy: 0.8641 - val_loss: 0.1004 - val_accuracy: 0.8677\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1020 - accuracy: 0.8649 - val_loss: 0.0963 - val_accuracy: 0.8713\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0998 - accuracy: 0.8673 - val_loss: 0.1055 - val_accuracy: 0.8582\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0991 - accuracy: 0.8679 - val_loss: 0.0950 - val_accuracy: 0.8735\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0973 - accuracy: 0.8710 - val_loss: 0.0993 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0974 - accuracy: 0.8713 - val_loss: 0.0994 - val_accuracy: 0.8673\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0970 - accuracy: 0.8713 - val_loss: 0.0940 - val_accuracy: 0.8785\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0978 - accuracy: 0.8702 - val_loss: 0.0919 - val_accuracy: 0.8797\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0958 - accuracy: 0.8723 - val_loss: 0.0914 - val_accuracy: 0.8790\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0939 - accuracy: 0.8760 - val_loss: 0.0941 - val_accuracy: 0.8746\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0931 - accuracy: 0.8775 - val_loss: 0.0908 - val_accuracy: 0.8792\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0918 - accuracy: 0.8781 - val_loss: 0.0905 - val_accuracy: 0.8807\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0917 - accuracy: 0.8784 - val_loss: 0.0874 - val_accuracy: 0.8866\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0914 - accuracy: 0.8794 - val_loss: 0.0998 - val_accuracy: 0.8645\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0891 - accuracy: 0.8814 - val_loss: 0.0871 - val_accuracy: 0.8872\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 74s 241ms/step - loss: 0.0884 - accuracy: 0.8836 - val_loss: 0.0952 - val_accuracy: 0.8718\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0884 - accuracy: 0.8832 - val_loss: 0.0834 - val_accuracy: 0.8907\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0868 - accuracy: 0.8851 - val_loss: 0.0878 - val_accuracy: 0.8853\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0881 - accuracy: 0.8840 - val_loss: 0.0805 - val_accuracy: 0.8969\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0851 - accuracy: 0.8882 - val_loss: 0.0897 - val_accuracy: 0.8796\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0851 - accuracy: 0.8883 - val_loss: 0.0869 - val_accuracy: 0.8862\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0846 - accuracy: 0.8886 - val_loss: 0.0810 - val_accuracy: 0.8942\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0843 - accuracy: 0.8891 - val_loss: 0.0814 - val_accuracy: 0.8919\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0831 - accuracy: 0.8908 - val_loss: 0.0825 - val_accuracy: 0.8917\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0743 - accuracy: 0.9056 - val_loss: 0.0722 - val_accuracy: 0.9085\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0729 - accuracy: 0.9072 - val_loss: 0.0720 - val_accuracy: 0.9089\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0730 - accuracy: 0.9073 - val_loss: 0.0725 - val_accuracy: 0.9074\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Half DeepWriter - 90K - RGB - Crossentropy - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/2ab2yq59\" target=\"_blank\">lively-dust-94</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"Binary Crossentropy\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 96s 257ms/step - loss: 0.6322 - accuracy: 0.5819 - val_loss: 0.6022 - val_accuracy: 0.6479\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.5784 - accuracy: 0.6896 - val_loss: 0.5426 - val_accuracy: 0.7005\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.5210 - accuracy: 0.7400 - val_loss: 0.5009 - val_accuracy: 0.7491\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4956 - accuracy: 0.7622 - val_loss: 0.4810 - val_accuracy: 0.7766\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4805 - accuracy: 0.7714 - val_loss: 0.4682 - val_accuracy: 0.7868\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.4749 - accuracy: 0.7766 - val_loss: 0.4539 - val_accuracy: 0.7866\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.4490 - accuracy: 0.7979 - val_loss: 0.4356 - val_accuracy: 0.8104\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4253 - accuracy: 0.8143 - val_loss: 0.4098 - val_accuracy: 0.8236\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4088 - accuracy: 0.8247 - val_loss: 0.4267 - val_accuracy: 0.8070\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4111 - accuracy: 0.8178 - val_loss: 0.4082 - val_accuracy: 0.8240\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.4027 - accuracy: 0.8215 - val_loss: 0.4099 - val_accuracy: 0.8178\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3945 - accuracy: 0.8252 - val_loss: 0.3829 - val_accuracy: 0.8315\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3821 - accuracy: 0.8339 - val_loss: 0.3812 - val_accuracy: 0.8320\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3743 - accuracy: 0.8375 - val_loss: 0.3635 - val_accuracy: 0.8419\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3629 - accuracy: 0.8448 - val_loss: 0.3520 - val_accuracy: 0.8522\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3626 - accuracy: 0.8440 - val_loss: 0.3419 - val_accuracy: 0.8586\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3549 - accuracy: 0.8487 - val_loss: 0.3449 - val_accuracy: 0.8509\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.3419 - val_accuracy: 0.8520\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3427 - accuracy: 0.8549 - val_loss: 0.3325 - val_accuracy: 0.8608\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.3433 - accuracy: 0.8529 - val_loss: 0.3893 - val_accuracy: 0.8264\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3330 - accuracy: 0.8594 - val_loss: 0.3541 - val_accuracy: 0.8469\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3384 - accuracy: 0.8551 - val_loss: 0.3259 - val_accuracy: 0.8618\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3299 - accuracy: 0.8602 - val_loss: 0.3176 - val_accuracy: 0.8673\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3210 - accuracy: 0.8654 - val_loss: 0.3244 - val_accuracy: 0.8613\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3248 - accuracy: 0.8632 - val_loss: 0.3228 - val_accuracy: 0.8652\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3215 - accuracy: 0.8647 - val_loss: 0.3144 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3144 - accuracy: 0.8691 - val_loss: 0.3386 - val_accuracy: 0.8559\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3201 - accuracy: 0.8650 - val_loss: 0.3050 - val_accuracy: 0.8741\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.3145 - accuracy: 0.8677 - val_loss: 0.3149 - val_accuracy: 0.8682\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3082 - accuracy: 0.8720 - val_loss: 0.2956 - val_accuracy: 0.8770\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.3082 - accuracy: 0.8724 - val_loss: 0.3206 - val_accuracy: 0.8612\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 75s 243ms/step - loss: 0.3048 - accuracy: 0.8734 - val_loss: 0.2894 - val_accuracy: 0.8833\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.3044 - accuracy: 0.8731 - val_loss: 0.3174 - val_accuracy: 0.8657\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2971 - accuracy: 0.8769 - val_loss: 0.2860 - val_accuracy: 0.8831\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2990 - accuracy: 0.8756 - val_loss: 0.2890 - val_accuracy: 0.8802\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2941 - accuracy: 0.8783 - val_loss: 0.3042 - val_accuracy: 0.8731\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2960 - accuracy: 0.8776 - val_loss: 0.2760 - val_accuracy: 0.8875\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2925 - accuracy: 0.8782 - val_loss: 0.2775 - val_accuracy: 0.8870\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2912 - accuracy: 0.8792 - val_loss: 0.2727 - val_accuracy: 0.8905\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2881 - accuracy: 0.8811 - val_loss: 0.3010 - val_accuracy: 0.8732\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2844 - accuracy: 0.8836 - val_loss: 0.2704 - val_accuracy: 0.8890\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2802 - accuracy: 0.8863 - val_loss: 0.2607 - val_accuracy: 0.8946\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2818 - accuracy: 0.8840 - val_loss: 0.2648 - val_accuracy: 0.8935\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2745 - accuracy: 0.8869 - val_loss: 0.2602 - val_accuracy: 0.8958\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2767 - accuracy: 0.8868 - val_loss: 0.2683 - val_accuracy: 0.8919\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2721 - accuracy: 0.8889 - val_loss: 0.2650 - val_accuracy: 0.8925\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2703 - accuracy: 0.8887 - val_loss: 0.2613 - val_accuracy: 0.8919\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.2682 - accuracy: 0.8903 - val_loss: 0.2693 - val_accuracy: 0.8876\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2598 - accuracy: 0.8950 - val_loss: 0.2493 - val_accuracy: 0.9002\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.2637 - accuracy: 0.8928 - val_loss: 0.2479 - val_accuracy: 0.9015\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}