{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from helper_functions import get_classification_report\n",
    "from helper_functions import create_tf_data_datasets_contrastive\n",
    "from helper_functions import create_tf_data_testset_contrastive\n",
    "from helper_functions import euclidean_distance\n",
    "from helper_functions import contrastive_loss\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras import mixed_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def AlexNet(height, width, channels):\n",
    "\n",
    "    X_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    X = keras.layers.Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 ,name='bn1')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn4')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = keras.layers.MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
    "\n",
    "    X = keras.layers.Flatten()(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
    "\n",
    "    X = keras.layers.Dense(4096, activation = 'sigmoid', name = 'fc1')(X)\n",
    "\n",
    "    model = keras.models.Model(inputs = X_input, outputs = X, name='AlexNet')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def half_deep_writer(height, width, channels):\n",
    "\n",
    "    input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    x = keras.layers.Conv2D(96, kernel_size=5, strides=2, activation='relu')(input)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding=\"valid\", activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"valid\",  activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "    output = keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "    model = keras.models.Model(input, output)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alexnet - 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/177pjp53\" target=\"_blank\">glamorous-dream-76</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Alexnet - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 69s 180ms/step - loss: 0.2205 - accuracy: 0.6626 - val_loss: 0.2291 - val_accuracy: 0.6202\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2128 - accuracy: 0.6694 - val_loss: 0.2588 - val_accuracy: 0.5252\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2090 - accuracy: 0.6741 - val_loss: 0.2761 - val_accuracy: 0.6213\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2152 - accuracy: 0.6686 - val_loss: 0.2653 - val_accuracy: 0.4989\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2157 - accuracy: 0.6663 - val_loss: 0.2749 - val_accuracy: 0.5853\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2092 - accuracy: 0.6758 - val_loss: 0.2726 - val_accuracy: 0.5025\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2087 - accuracy: 0.6708 - val_loss: 0.2078 - val_accuracy: 0.6689\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2054 - accuracy: 0.6774 - val_loss: 0.2029 - val_accuracy: 0.6791\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2022 - accuracy: 0.6809 - val_loss: 0.1983 - val_accuracy: 0.6876\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.2015 - accuracy: 0.6804 - val_loss: 0.2001 - val_accuracy: 0.6796\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1991 - accuracy: 0.6841 - val_loss: 0.2000 - val_accuracy: 0.6770\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1979 - accuracy: 0.6852 - val_loss: 0.2016 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1983 - accuracy: 0.6830 - val_loss: 0.1963 - val_accuracy: 0.6863\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1978 - accuracy: 0.6815 - val_loss: 0.1982 - val_accuracy: 0.6769\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1976 - accuracy: 0.6835 - val_loss: 0.1962 - val_accuracy: 0.6848\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1956 - accuracy: 0.6835 - val_loss: 0.2098 - val_accuracy: 0.6811\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1961 - accuracy: 0.6827 - val_loss: 0.2010 - val_accuracy: 0.6744\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1945 - accuracy: 0.6847 - val_loss: 0.1929 - val_accuracy: 0.6828\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1940 - accuracy: 0.6845 - val_loss: 0.1915 - val_accuracy: 0.6885\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1927 - accuracy: 0.6970 - val_loss: 0.2014 - val_accuracy: 0.6873\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1915 - accuracy: 0.7153 - val_loss: 0.1940 - val_accuracy: 0.7085\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1914 - accuracy: 0.7144 - val_loss: 0.1889 - val_accuracy: 0.7209\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1899 - accuracy: 0.7181 - val_loss: 0.2192 - val_accuracy: 0.6637\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1896 - accuracy: 0.7192 - val_loss: 0.1880 - val_accuracy: 0.7184\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1890 - accuracy: 0.7184 - val_loss: 0.1887 - val_accuracy: 0.7182\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1878 - accuracy: 0.7243 - val_loss: 0.1890 - val_accuracy: 0.7204\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1869 - accuracy: 0.7266 - val_loss: 0.1876 - val_accuracy: 0.7314\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1848 - accuracy: 0.7314 - val_loss: 0.1871 - val_accuracy: 0.7230\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1839 - accuracy: 0.7327 - val_loss: 0.1829 - val_accuracy: 0.7376\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1843 - accuracy: 0.7338 - val_loss: 0.1847 - val_accuracy: 0.7294\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1823 - accuracy: 0.7381 - val_loss: 0.1776 - val_accuracy: 0.7461\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1803 - accuracy: 0.7425 - val_loss: 0.1788 - val_accuracy: 0.7421\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1798 - accuracy: 0.7403 - val_loss: 0.1768 - val_accuracy: 0.7455\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1776 - accuracy: 0.7448 - val_loss: 0.1844 - val_accuracy: 0.7277\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1742 - accuracy: 0.7555 - val_loss: 0.1915 - val_accuracy: 0.7032\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1716 - accuracy: 0.7589 - val_loss: 0.1761 - val_accuracy: 0.7428\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1720 - accuracy: 0.7583 - val_loss: 0.1888 - val_accuracy: 0.7394\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1673 - accuracy: 0.7673 - val_loss: 0.1803 - val_accuracy: 0.7455\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1623 - accuracy: 0.7781 - val_loss: 0.1721 - val_accuracy: 0.7663\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1593 - accuracy: 0.7829 - val_loss: 0.1614 - val_accuracy: 0.7816\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1568 - accuracy: 0.7930 - val_loss: 0.1592 - val_accuracy: 0.7950\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1550 - accuracy: 0.7947 - val_loss: 0.1583 - val_accuracy: 0.7922\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1548 - accuracy: 0.7950 - val_loss: 0.1633 - val_accuracy: 0.7671\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1522 - accuracy: 0.7995 - val_loss: 0.1755 - val_accuracy: 0.7661\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1520 - accuracy: 0.8014 - val_loss: 0.1831 - val_accuracy: 0.7432\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1509 - accuracy: 0.8059 - val_loss: 0.1949 - val_accuracy: 0.6898\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1495 - accuracy: 0.8064 - val_loss: 0.1752 - val_accuracy: 0.7414\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1470 - accuracy: 0.8127 - val_loss: 0.1487 - val_accuracy: 0.8140\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 55s 175ms/step - loss: 0.1471 - accuracy: 0.8141 - val_loss: 0.1475 - val_accuracy: 0.8105\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 55s 176ms/step - loss: 0.1459 - accuracy: 0.8147 - val_loss: 0.1437 - val_accuracy: 0.8192\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Half DeepWriter - 90K - RGB - Contrastive - Eucledian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor_images_path = \"npz_datasets/pairs_90k_224_224/anchor\"\n",
    "positive_images_path = \"npz_datasets/pairs_90k_224_224/positive\"\n",
    "width, height, channels = 224, 224, 3\n",
    "batch_size = 256\n",
    "train_dataset, val_dataset = create_tf_data_datasets_contrastive(anchor_images_path, positive_images_path, batch_size, height, width, rgb=True)\n",
    "\n",
    "anchor_images_test_path = \"npz_datasets/test_pairs_224_224/anchor\"\n",
    "positive_images_test_path = \"npz_datasets/test_pairs_224_224/positive\"\n",
    "test_dataset = create_tf_data_testset_contrastive(anchor_images_test_path, positive_images_test_path, height, width, rgb=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschauppi\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/schauppi/Architecture_1/runs/3qa9jwgq\" target=\"_blank\">major-water-79</a></strong> to <a href=\"https://wandb.ai/schauppi/Architecture_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Architecture_1\",\n",
    "                 config={\"learning_rate\": 0.001,\n",
    "                         \"momentum\": 0.5,\n",
    "                         \"otimizer\": \"Adam\",\n",
    "                         \"loss_function\": \"contrastive loss\",\n",
    "                         \"epochs\": 50,\n",
    "                         \"architecture\": \"Half Deep Writer - 90k - RGB\"})\n",
    "\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 95s 255ms/step - loss: 0.2202 - accuracy: 0.5964 - val_loss: 0.2030 - val_accuracy: 0.6824\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.1987 - accuracy: 0.7048 - val_loss: 0.1860 - val_accuracy: 0.7404\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1810 - accuracy: 0.7480 - val_loss: 0.1754 - val_accuracy: 0.7636\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1695 - accuracy: 0.7690 - val_loss: 0.1634 - val_accuracy: 0.7850\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1624 - accuracy: 0.7792 - val_loss: 0.1557 - val_accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1552 - accuracy: 0.7925 - val_loss: 0.1533 - val_accuracy: 0.7907\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1479 - accuracy: 0.8036 - val_loss: 0.1399 - val_accuracy: 0.8239\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.1416 - accuracy: 0.8117 - val_loss: 0.1412 - val_accuracy: 0.8131\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1354 - accuracy: 0.8206 - val_loss: 0.1322 - val_accuracy: 0.8242\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1318 - accuracy: 0.8254 - val_loss: 0.1289 - val_accuracy: 0.8316\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1326 - accuracy: 0.8225 - val_loss: 0.1515 - val_accuracy: 0.7873\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1404 - accuracy: 0.8052 - val_loss: 0.1226 - val_accuracy: 0.8380\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1275 - accuracy: 0.8279 - val_loss: 0.1219 - val_accuracy: 0.8376\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1215 - accuracy: 0.8372 - val_loss: 0.1148 - val_accuracy: 0.8485\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1192 - accuracy: 0.8406 - val_loss: 0.1165 - val_accuracy: 0.8438\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1165 - accuracy: 0.8447 - val_loss: 0.1126 - val_accuracy: 0.8506\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1133 - accuracy: 0.8503 - val_loss: 0.1162 - val_accuracy: 0.8402\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.1110 - accuracy: 0.8530 - val_loss: 0.1097 - val_accuracy: 0.8538\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1079 - accuracy: 0.8581 - val_loss: 0.1058 - val_accuracy: 0.8606\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1069 - accuracy: 0.8585 - val_loss: 0.1048 - val_accuracy: 0.8635\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1060 - accuracy: 0.8582 - val_loss: 0.1006 - val_accuracy: 0.8680\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1050 - accuracy: 0.8612 - val_loss: 0.1041 - val_accuracy: 0.8618\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1019 - accuracy: 0.8646 - val_loss: 0.0987 - val_accuracy: 0.8712\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1024 - accuracy: 0.8641 - val_loss: 0.1004 - val_accuracy: 0.8677\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.1020 - accuracy: 0.8649 - val_loss: 0.0963 - val_accuracy: 0.8713\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0998 - accuracy: 0.8673 - val_loss: 0.1055 - val_accuracy: 0.8582\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0991 - accuracy: 0.8679 - val_loss: 0.0950 - val_accuracy: 0.8735\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0973 - accuracy: 0.8710 - val_loss: 0.0993 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0974 - accuracy: 0.8713 - val_loss: 0.0994 - val_accuracy: 0.8673\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0970 - accuracy: 0.8713 - val_loss: 0.0940 - val_accuracy: 0.8785\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0978 - accuracy: 0.8702 - val_loss: 0.0919 - val_accuracy: 0.8797\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0958 - accuracy: 0.8723 - val_loss: 0.0914 - val_accuracy: 0.8790\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0939 - accuracy: 0.8760 - val_loss: 0.0941 - val_accuracy: 0.8746\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0931 - accuracy: 0.8775 - val_loss: 0.0908 - val_accuracy: 0.8792\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0918 - accuracy: 0.8781 - val_loss: 0.0905 - val_accuracy: 0.8807\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0917 - accuracy: 0.8784 - val_loss: 0.0874 - val_accuracy: 0.8866\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0914 - accuracy: 0.8794 - val_loss: 0.0998 - val_accuracy: 0.8645\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0891 - accuracy: 0.8814 - val_loss: 0.0871 - val_accuracy: 0.8872\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 74s 241ms/step - loss: 0.0884 - accuracy: 0.8836 - val_loss: 0.0952 - val_accuracy: 0.8718\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0884 - accuracy: 0.8832 - val_loss: 0.0834 - val_accuracy: 0.8907\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0868 - accuracy: 0.8851 - val_loss: 0.0878 - val_accuracy: 0.8853\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0881 - accuracy: 0.8840 - val_loss: 0.0805 - val_accuracy: 0.8969\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0851 - accuracy: 0.8882 - val_loss: 0.0897 - val_accuracy: 0.8796\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0851 - accuracy: 0.8883 - val_loss: 0.0869 - val_accuracy: 0.8862\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0846 - accuracy: 0.8886 - val_loss: 0.0810 - val_accuracy: 0.8942\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0843 - accuracy: 0.8891 - val_loss: 0.0814 - val_accuracy: 0.8919\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 74s 242ms/step - loss: 0.0831 - accuracy: 0.8908 - val_loss: 0.0825 - val_accuracy: 0.8917\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0743 - accuracy: 0.9056 - val_loss: 0.0722 - val_accuracy: 0.9085\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 74s 243ms/step - loss: 0.0729 - accuracy: 0.9072 - val_loss: 0.0720 - val_accuracy: 0.9089\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 75s 244ms/step - loss: 0.0730 - accuracy: 0.9073 - val_loss: 0.0725 - val_accuracy: 0.9074\n"
     ]
    }
   ],
   "source": [
    "model = half_deep_writer(height, width, channels)\n",
    "\n",
    "left_input = keras.layers.Input(shape=(height, width, channels))\n",
    "right_input = keras.layers.Input(shape=(height, width, channels))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "distance = keras.layers.Lambda(euclidean_distance)([encoded_l, encoded_r])\n",
    "\n",
    "prediction = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese_model = keras.models.Model([left_input, right_input], outputs=prediction)\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_siamese_model = siamese_model.fit(train_dataset, epochs=config.epochs, validation_data=val_dataset, callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5),WandbCallback()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "precision, recall, f1_score, preds_wandb, labels = get_classification_report(test_dataset, siamese_model)\n",
    "wandb.log({\"roc\": wandb.plot.roc_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({\"pr\": wandb.plot.pr_curve(labels, preds_wandb, labels=None, classes_to_plot=None)})\n",
    "wandb.log({'Precision': precision})\n",
    "wandb.log({'Recall': recall})\n",
    "wandb.log({'F1 - Score': f1_score})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}